ğŸ“„ 1ï¸âƒ£ README.md
# Acodeâ€‘AIâ€‘Assist  â€“  AIâ€‘powered CLI for the Acode editor

A tiny Acode pluginâ€‘CLI that lets you **talk to more than 27 AI providers** (OpenAI, Anthropic, Gemini, Llamaâ€‘2, â€¦) and **pick any model** from a catalog that can hold hundredsâ€‘ofâ€‘thousands of entries.  
The plugin runs completely inside Acodeâ€™s builtâ€‘in terminal, inserts the answer at the cursor position, and (optionally) executes safe JavaScript code in a sandbox.
# Acodeâ€‘AIâ€‘Assist  â€“  AIâ€‘powered CLI for the Acode editor

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **Modelâ€‘catalog driven** â€“ a remote `catalog.json` lists every model you own; the CLI can `--list` them, filter by tags, and select any model with `--model <id>`. |
| **Multiple providers** â€“ OpenAI, Anthropic, Google Gemini, any OpenAIâ€‘compatible endpoint, selfâ€‘hosted Llamaâ€‘2, etc. |
| **Zeroâ€‘leak API keys** â€“ only `ACODE_â€¦` variables are baked into the final zip; real provider keys stay in the device keystore (`.env` or OS keychain). |
| **Rate limiting & retries** â€“ perâ€‘provider `rateâ€‘limiter-flexible` guarantees you never exceed plan quotas. |
| **Content moderation** â€“ every answer passes through OpenAIâ€™s moderation endpoint (or any custom filter) before it reaches the editor. |
| **Sandboxed code execution** â€“ optional `vm2` sandbox prevents malicious code from touching the file system or network. |
| **Encrypted audit log** â€“ each request/response pair is stored locally in an AESâ€‘256â€‘GCM file (`~/.acode_ai_audit.log.enc`). |
| **Liveâ€‘reload dev server** â€“ `npm run dev` watches files and refreshes the Acode preview automatically. |
| **Oneâ€‘click production build** â€“ `npm run build` creates a readyâ€‘toâ€‘publish `<plugin>.zip`. |

---

## ğŸ“¦ Installation

```bash
# 1ï¸âƒ£ Clone the repo
git clone https://github.com/yourâ€‘name/acodeâ€‘aiâ€‘assist.git
cd acodeâ€‘aiâ€‘assist

# 2ï¸âƒ£ Install Node dependencies
npm ci

# 3ï¸âƒ£ Create a .env file (see below)
cp .env.example .env
# edit the file â€“ add only the keys you actually own


ğŸš€ Usage
Command	What it does
ai <your naturalâ€‘language request>	Uses the cheapest chat model from the catalog.
ai --model anthropic:claude-3-5-sonnet <prompt>	Forces that exact model.
ai --list	Prints a table of all models in the catalog (IDs, provider, tags, price).
ai --list --tag code	Shows only models that advertise the code tag.
ai --help	Shows the help banner.
ai --model llama2:7b-chat <prompt> + ACODE_ALLOW_EXEC=1	If the answer starts with a shebang (#!/usr/bin/env node) it will be run inside a vm2 sandbox and the sandbox output will be printed.
All answers are moderated before being inserted. If a response is flagged, youâ€™ll see a toast warning and the text will not be written to the editor.

ğŸ” Security & Hardening
Concern	Builtâ€‘in mitigation
API key leakage	Keys are read only from process.env at runtime â€“ they are never bundled into the final zip.
Calling a provider you donâ€™t own	catalog.json only contains entries you have added; the CLI validates that the provider appears in ACODE_AVAILABLE_PROVIDERS.
Exceeding rate limits / unexpected bills	rateâ€‘limiter-flexible enforces perâ€‘provider limits (configurable in src/networkGuard.js).
Malicious LLM output	1ï¸âƒ£ Moderation endpoint (src/moderation.js). 2ï¸âƒ£ Optional sandboxed JS execution (src/runner.js). 3ï¸âƒ£ Sanitisation of HTML (sanitize-html).
Audit tampering	Local audit log is AESâ€‘256â€‘GCM encrypted with a passphrase you keep offline (src/audit.js).
Manâ€‘inâ€‘theâ€‘middle on the catalog	The catalog URL should be served over HTTPS; you can also pin a SHAâ€‘256 hash of the file and verify it on download (add a simple checksum step in catalogClient.js if you wish).
ğŸ› ï¸ Extending the plugin
Add a new provider

Add a provider entry to catalog.json (see the sample below).
Create a file src/providerAdapters/<type>Adapter.js that exports buildRequest({model, provider, prompt}).
The CLI will automatically discover it because the adapter name matches provider.type.
Add tags / extra metadata

Extend each model object in catalog.json with any fields you like (tags, price, description).
Use ai --list --tag <myTag> to filter on those tags.
Custom safety filter

Replace or augment src/moderation.js with a call to a selfâ€‘hosted hateâ€‘speech filter, a locallyâ€‘run toxicâ€‘comment model, etc.
Replace the sandbox

If you need a stricter environment (Docker, Firecracker, etc.) replace the runJS function in src/runner.js with your own executor; keep the same return shape {stdout,stderr,error}.
ğŸ“¦ Production build & publishing
npm run build          # â†’ creates dist/ + <pluginâ€‘name>.zip
# In Acode:
#   Settings â†’ Plugins â†’ Import â†’ select the generated zip
#   Enable the plugin â†’ open the Terminal â†’ start using â€œai â€¦â€
The generated zip contains only:

dist/ (minified bundle + static assets)
manifest.json (Acodeâ€‘required metadata)
No secrets, no catalog data, no node_modules â€“ everything you need is inside the bundle.

ğŸ“œ License
MIT Â© 2024â€¯â€“â€¯yourâ€‘name. Feel free to fork, improve, or embed this plugin in any project you like.

ğŸ™ Acknowledgements
esbuild â€“ ultraâ€‘fast bundler that powers the build pipeline.
Secondâ€‘Opinion â€“ inspiration for a multiâ€‘agent LLM router (the catalog concept).
OpenAI, Anthropic, Google Gemini, Llamaâ€‘2 â€“ the providers that make this possible.
